INFO 12-02 22:21:05 [__init__.py:39] Available plugins for group vllm.platform_plugins:
INFO 12-02 22:21:05 [__init__.py:41] - optimum_neuron -> optimum.neuron.vllm.plugin:register
INFO 12-02 22:21:05 [__init__.py:44] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  from .mappings import (
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  from .mappings import (
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  from .mappings import (
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
INFO:Neuron:Optimum Neuron platform plugin registered for vLLM.
INFO:Neuron:Optimum Neuron platform plugin registered for vLLM.
INFO 12-02 22:21:05 [__init__.py:235] Platform plugin optimum_neuron is activated
WARNING 12-02 22:21:05 [_custom_ops.py:20] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
WARNING 12-02 22:21:07 [__init__.py:1441] argument 'device' is deprecated
INFO 12-02 22:21:07 [api_server.py:1395] vLLM API server version 0.9.2
INFO 12-02 22:21:07 [cli_args.py:325] non-default args: {'port': 8080, 'model': '/home/ubuntu/environment/ml/qwen/compiled_model', 'task': 'generate', 'dtype': 'bfloat16', 'max_model_len': 2048, 'tensor_parallel_size': 2, 'device': 'neuron', 'max_num_seqs': 4}
INFO 12-02 22:21:13 [config.py:1472] Using max model len 2048
WARNING 12-02 22:21:13 [arg_utils.py:1735] device type=neuron is not supported by the V1 Engine. Falling back to V0. 
INFO 12-02 22:21:15 [api_server.py:268] Started engine process with PID 60701
INFO 12-02 22:21:20 [__init__.py:39] Available plugins for group vllm.platform_plugins:
INFO 12-02 22:21:20 [__init__.py:41] - optimum_neuron -> optimum.neuron.vllm.plugin:register
INFO 12-02 22:21:20 [__init__.py:44] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  from .mappings import (
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  from .mappings import (
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  from .mappings import (
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  component, error = import_nki(config)
INFO:Neuron:Optimum Neuron platform plugin registered for vLLM.
INFO:Neuron:Optimum Neuron platform plugin registered for vLLM.
INFO 12-02 22:21:20 [__init__.py:235] Platform plugin optimum_neuron is activated
WARNING 12-02 22:21:21 [_custom_ops.py:20] Failed to import from vllm._C with ImportError('libcuda.so.1: cannot open shared object file: No such file or directory')
INFO 12-02 22:21:21 [llm_engine.py:230] Initializing a V0 LLM engine (v0.9.2) with config: model='/home/ubuntu/environment/ml/qwen/compiled_model', speculative_config=None, tokenizer='/home/ubuntu/environment/ml/qwen/compiled_model', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cpu, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/ubuntu/environment/ml/qwen/compiled_model, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":[],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"max_capture_size":4,"local_cache_dir":null}, use_cached_outputs=True, 
INFO 12-02 22:21:22 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  from ..attention.gqa import (
/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.
  from ..backend.modules.attention.attention_base import NeuronAttentionBase
INFO:Neuron:Loading sharded checkpoint from /home/ubuntu/environment/ml/qwen/compiled_model/checkpoint/weights
2025-Dec-02 22:21:22.383108 60701:60701 ERROR   NRT:nrt_allocate_neuron_cores               Logical Neuron Core(s) not available - Requested:2 Available:0 Logical Core size 1
2025-Dec-02 22:21:22.393064 60701:60701 ERROR   NRT:nrt_infodump                            Neuron runtime information - please include in any support request:
2025-Dec-02 22:21:22.400774 60701:60701 ERROR   NRT:nrt_infodump                            ------------->8------------[ cut here ]------------>8-------------
2025-Dec-02 22:21:22.408389 60701:60701 ERROR   NRT:nrt_infodump                            NRT version: 2.27.23.0 (8deec4dbf8b5f1aa400128e80861ebd415a45303)
2025-Dec-02 22:21:22.416000 60701:60701 ERROR   NRT:nrt_infodump                            Embedded FW version: unknown (unknown)
2025-Dec-02 22:21:22.422754 60701:60701 ERROR   NRT:nrt_infodump                            CCOM not loaded
2025-Dec-02 22:21:22.428833 60701:60701 ERROR   NRT:nrt_infodump                            NCFW version: 2.27.0.0 (3b87b9472bc9b6bc51479b9bc14c042fa62e7c7e)
2025-Dec-02 22:21:22.436402 60701:60701 ERROR   NRT:nrt_infodump                            Instance ID: i-042d58b79cbc9d725
2025-Dec-02 22:21:22.442963 60701:60701 ERROR   NRT:nrt_infodump                            Cluster ID: N/A
2025-Dec-02 22:21:22.449023 60701:60701 ERROR   NRT:nrt_infodump                            Kernel: Linux 6.8.0-1031-aws #33~22.04.1-Ubuntu SMP Thu Jun 26 14:22:30 UTC 2025
2025-Dec-02 22:21:22.458578 60701:60701 ERROR   NRT:nrt_infodump                            Nodename: ip-192-168-0-75
2025-Dec-02 22:21:22.464954 60701:60701 ERROR   NRT:nrt_infodump                            Driver version: 2.23.9.0

2025-Dec-02 22:21:22.473323 60701:60701 ERROR   NRT:nrt_infodump                            Failure: NRT_FAILURE in nrt_init()
2025-Dec-02 22:21:22.479973 60701:60701 ERROR   NRT:nrt_infodump                            Environment:
2025-Dec-02 22:21:22.485948 60701:60701 ERROR   NRT:nrt_infodump                                NEURON_LIBRARY_PATH=/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/libneuronxla/libneuronpjrt.so
2025-Dec-02 22:21:22.497021 60701:60701 ERROR   NRT:nrt_infodump                                NEURON_RT_ROOT_COMM_ID=localhost:62182
2025-Dec-02 22:21:22.503981 60701:60701 ERROR   NRT:nrt_infodump                                NEURON_RT_DISABLE_EXECUTION_BARRIER=1
2025-Dec-02 22:21:22.510880 60701:60701 ERROR   NRT:nrt_infodump                                NEURON_RT_NUMERICAL_ERRORS_VERBOSITY=none
2025-Dec-02 22:21:22.517883 60701:60701 ERROR   NRT:nrt_infodump                            -------------8<-----------[ cut to here ]-----------8<------------
ERROR 12-02 22:21:22 [engine.py:458] The following operation failed in the TorchScript interpreter.
ERROR 12-02 22:21:22 [engine.py:458] Traceback of TorchScript, serialized code (most recent call last):
ERROR 12-02 22:21:22 [engine.py:458]   File "code/__torch__/neuronx_distributed/trace/spmd.py", line 154, in initialize
ERROR 12-02 22:21:22 [engine.py:458]     start_rank = int(start_rank_tensor)
ERROR 12-02 22:21:22 [engine.py:458]     weight_loader = self.weight_loader
ERROR 12-02 22:21:22 [engine.py:458]     _21 = (weight_loader).forward(checkpoint, False, )
ERROR 12-02 22:21:22 [engine.py:458]            ~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
ERROR 12-02 22:21:22 [engine.py:458]     self.weights = _21
ERROR 12-02 22:21:22 [engine.py:458]     state_initializer = self.state_initializer
ERROR 12-02 22:21:22 [engine.py:458] 
ERROR 12-02 22:21:22 [engine.py:458] Traceback of TorchScript, original code (most recent call last):
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/trace/spmd.py", line 129, in initialize
ERROR 12-02 22:21:22 [engine.py:458]         start_rank = torch.ops.aten.Int(start_rank_tensor)
ERROR 12-02 22:21:22 [engine.py:458]         if self.weight_loader is not None:
ERROR 12-02 22:21:22 [engine.py:458]             self.weights = self.weight_loader.forward(checkpoint, False)
ERROR 12-02 22:21:22 [engine.py:458]                            ~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
ERROR 12-02 22:21:22 [engine.py:458]         else:
ERROR 12-02 22:21:22 [engine.py:458]             self.weights = torch.ops.neuron._parallel_load(checkpoint)
ERROR 12-02 22:21:22 [engine.py:458] RuntimeError: The PyTorch Neuron Runtime could not be initialized. Neuron Driver issues are logged
ERROR 12-02 22:21:22 [engine.py:458] to your system logs. See the Neuron Runtime's troubleshooting guide for help on this
ERROR 12-02 22:21:22 [engine.py:458] topic: https://awsdocs-neuron.readthedocs-hosted.com/en/latest/
ERROR 12-02 22:21:22 [engine.py:458] Traceback (most recent call last):
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py", line 446, in run_mp_engine
ERROR 12-02 22:21:22 [engine.py:458]     engine = MQLLMEngine.from_vllm_config(
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py", line 133, in from_vllm_config
ERROR 12-02 22:21:22 [engine.py:458]     return cls(
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py", line 87, in __init__
ERROR 12-02 22:21:22 [engine.py:458]     self.engine = LLMEngine(*args, **kwargs)
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 265, in __init__
ERROR 12-02 22:21:22 [engine.py:458]     self.model_executor = executor_class(vllm_config=vllm_config)
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 53, in __init__
ERROR 12-02 22:21:22 [engine.py:458]     self._init_executor()
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 48, in _init_executor
ERROR 12-02 22:21:22 [engine.py:458]     self.collective_rpc("load_model")
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 57, in collective_rpc
ERROR 12-02 22:21:22 [engine.py:458]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/utils/__init__.py", line 2736, in run_method
ERROR 12-02 22:21:22 [engine.py:458]     return func(*args, **kwargs)
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/vllm/worker.py", line 70, in load_model
ERROR 12-02 22:21:22 [engine.py:458]     self.model_runner.load_model()
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/vllm/runner.py", line 87, in load_model
ERROR 12-02 22:21:22 [engine.py:458]     self.model = get_optimum_neuron_model(
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/vllm/model_loader.py", line 230, in get_optimum_neuron_model
ERROR 12-02 22:21:22 [engine.py:458]     neuron_model = NeuronModelForCausalLM.from_pretrained(
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/modeling_base.py", line 438, in from_pretrained
ERROR 12-02 22:21:22 [engine.py:458]     return from_pretrained_method(
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/modeling_decoder.py", line 278, in _from_pretrained
ERROR 12-02 22:21:22 [engine.py:458]     return cls._from_pretrained(model_id, config, **kwargs)
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/decoder/modeling_decoder.py", line 810, in _from_pretrained
ERROR 12-02 22:21:22 [engine.py:458]     model.load_weights(
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/pretrained_model.py", line 233, in load_weights
ERROR 12-02 22:21:22 [engine.py:458]     self._load_weights_from_path(checkpoint_path)
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/pretrained_model.py", line 218, in _load_weights_from_path
ERROR 12-02 22:21:22 [engine.py:458]     self._traced_model.nxd_model.initialize(weights, start_rank_tensor)
ERROR 12-02 22:21:22 [engine.py:458] RuntimeError: The following operation failed in the TorchScript interpreter.
ERROR 12-02 22:21:22 [engine.py:458] Traceback of TorchScript, serialized code (most recent call last):
ERROR 12-02 22:21:22 [engine.py:458]   File "code/__torch__/neuronx_distributed/trace/spmd.py", line 154, in initialize
ERROR 12-02 22:21:22 [engine.py:458]     start_rank = int(start_rank_tensor)
ERROR 12-02 22:21:22 [engine.py:458]     weight_loader = self.weight_loader
ERROR 12-02 22:21:22 [engine.py:458]     _21 = (weight_loader).forward(checkpoint, False, )
ERROR 12-02 22:21:22 [engine.py:458]            ~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
ERROR 12-02 22:21:22 [engine.py:458]     self.weights = _21
ERROR 12-02 22:21:22 [engine.py:458]     state_initializer = self.state_initializer
ERROR 12-02 22:21:22 [engine.py:458] 
ERROR 12-02 22:21:22 [engine.py:458] Traceback of TorchScript, original code (most recent call last):
ERROR 12-02 22:21:22 [engine.py:458]   File "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/trace/spmd.py", line 129, in initialize
ERROR 12-02 22:21:22 [engine.py:458]         start_rank = torch.ops.aten.Int(start_rank_tensor)
ERROR 12-02 22:21:22 [engine.py:458]         if self.weight_loader is not None:
ERROR 12-02 22:21:22 [engine.py:458]             self.weights = self.weight_loader.forward(checkpoint, False)
ERROR 12-02 22:21:22 [engine.py:458]                            ~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
ERROR 12-02 22:21:22 [engine.py:458]         else:
ERROR 12-02 22:21:22 [engine.py:458]             self.weights = torch.ops.neuron._parallel_load(checkpoint)
ERROR 12-02 22:21:22 [engine.py:458] RuntimeError: The PyTorch Neuron Runtime could not be initialized. Neuron Driver issues are logged
ERROR 12-02 22:21:22 [engine.py:458] to your system logs. See the Neuron Runtime's troubleshooting guide for help on this
ERROR 12-02 22:21:22 [engine.py:458] topic: https://awsdocs-neuron.readthedocs-hosted.com/en/latest/
ERROR 12-02 22:21:22 [engine.py:458] 
Process SpawnProcess-1:
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py", line 460, in run_mp_engine
    raise e from None
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py", line 446, in run_mp_engine
    engine = MQLLMEngine.from_vllm_config(
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py", line 133, in from_vllm_config
    return cls(
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/multiprocessing/engine.py", line 87, in __init__
    self.engine = LLMEngine(*args, **kwargs)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/engine/llm_engine.py", line 265, in __init__
    self.model_executor = executor_class(vllm_config=vllm_config)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/executor/executor_base.py", line 53, in __init__
    self._init_executor()
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 48, in _init_executor
    self.collective_rpc("load_model")
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/executor/uniproc_executor.py", line 57, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/utils/__init__.py", line 2736, in run_method
    return func(*args, **kwargs)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/vllm/worker.py", line 70, in load_model
    self.model_runner.load_model()
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/vllm/runner.py", line 87, in load_model
    self.model = get_optimum_neuron_model(
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/vllm/model_loader.py", line 230, in get_optimum_neuron_model
    neuron_model = NeuronModelForCausalLM.from_pretrained(
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/modeling_base.py", line 438, in from_pretrained
    return from_pretrained_method(
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/modeling_decoder.py", line 278, in _from_pretrained
    return cls._from_pretrained(model_id, config, **kwargs)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/decoder/modeling_decoder.py", line 810, in _from_pretrained
    model.load_weights(
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/pretrained_model.py", line 233, in load_weights
    self._load_weights_from_path(checkpoint_path)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/pretrained_model.py", line 218, in _load_weights_from_path
    self._traced_model.nxd_model.initialize(weights, start_rank_tensor)
RuntimeError: The following operation failed in the TorchScript interpreter.
Traceback of TorchScript, serialized code (most recent call last):
  File "code/__torch__/neuronx_distributed/trace/spmd.py", line 154, in initialize
    start_rank = int(start_rank_tensor)
    weight_loader = self.weight_loader
    _21 = (weight_loader).forward(checkpoint, False, )
           ~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
    self.weights = _21
    state_initializer = self.state_initializer

Traceback of TorchScript, original code (most recent call last):
  File "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/trace/spmd.py", line 129, in initialize
        start_rank = torch.ops.aten.Int(start_rank_tensor)
        if self.weight_loader is not None:
            self.weights = self.weight_loader.forward(checkpoint, False)
                           ~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE
        else:
            self.weights = torch.ops.neuron._parallel_load(checkpoint)
RuntimeError: The PyTorch Neuron Runtime could not be initialized. Neuron Driver issues are logged
to your system logs. See the Neuron Runtime's troubleshooting guide for help on this
topic: https://awsdocs-neuron.readthedocs-hosted.com/en/latest/

Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 1495, in <module>
    uvloop.run(run_server(args))
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/uvloop/__init__.py", line 69, in run
    return loop.run_until_complete(wrapper())
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/uvloop/__init__.py", line 48, in wrapper
    return await main
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 1431, in run_server
    await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 1451, in run_server_worker
    async with build_async_engine_client(args, client_config) as engine_client:
  File "/usr/lib/python3.10/contextlib.py", line 199, in __aenter__
    return await anext(self.gen)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 158, in build_async_engine_client
    async with build_async_engine_client_from_engine_args(
  File "/usr/lib/python3.10/contextlib.py", line 199, in __aenter__
    return await anext(self.gen)
  File "/opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/vllm/entrypoints/openai/api_server.py", line 291, in build_async_engine_client_from_engine_args
    raise RuntimeError(
RuntimeError: Engine process failed to start. See stack trace for the root cause.
